{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nxFZG8lhmWq",
        "outputId": "a162ba9e-02be-4802-fecb-830dcc9a3c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Combined Data.csv\")"
      ],
      "metadata": {
        "id": "YYKWqdYBiMG4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4JnUUSRnWGu",
        "outputId": "74c8f884-f43d-4710-829a-345822b4a985"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53043, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "6SEHdkoWiq6D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Lowercase, remove URLs, mentions, special chars, and stopwords\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+|@\\w+|#\\w+|[^a-z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    return ' '.join([t for t in tokens if t not in stop_words and len(t) > 2])\n",
        "\n",
        "# Apply preprocessing\n",
        "df['processed_statement'] = df['statement'].apply(preprocess_text)\n",
        "df = df[df['processed_statement'].str.len() > 0]  # Remove empty entries\n",
        "\n",
        "# Prepare features and labels\n",
        "X = df['processed_statement'].values\n",
        "label_encoder = LabelEncoder() # Define label_encoder here\n",
        "y = label_encoder.fit_transform(df['status'].values) # Fit label_encoder here\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "rQqz9IC9i0H6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_LENGTH = 100\n",
        "\n",
        "# Initialize and fit tokenizer\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to padded sequences\n",
        "X_train_padded = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=MAX_LENGTH, padding='post')\n",
        "X_test_padded = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=MAX_LENGTH, padding='post')"
      ],
      "metadata": {
        "id": "H3eTcmYnjaZA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_UNITS = 64\n",
        "NUM_CLASSES = len(set(y_train))  # You can use label_encoder.classes_ if needed\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "\n",
        "    SimpleRNN(RNN_UNITS, return_sequences=True, dropout=0.2),\n",
        "    SimpleRNN(RNN_UNITS // 2, dropout=0.2),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(NUM_CLASSES, activation='softmax' if NUM_CLASSES > 2 else 'sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy' if NUM_CLASSES > 2 else 'binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "X0QtMYgbj3Zq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True, verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.2, patience=5, min_lr=1e-4, verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    validation_data=(X_test_padded, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugCfm-2WkFbS",
        "outputId": "f11e8784-41b2-4e7b-dbd0-42ffae58d4ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.3190 - loss: 1.6745 - val_accuracy: 0.3783 - val_loss: 1.5630 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.3772 - loss: 1.5793 - val_accuracy: 0.3768 - val_loss: 1.5648 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.3231 - loss: 1.6377 - val_accuracy: 0.3631 - val_loss: 1.5729 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.3558 - loss: 1.5886 - val_accuracy: 0.3662 - val_loss: 1.6096 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.3618 - loss: 1.5829 - val_accuracy: 0.3709 - val_loss: 1.5442 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.3712 - loss: 1.5515 - val_accuracy: 0.3734 - val_loss: 1.5608 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.3733 - loss: 1.5583 - val_accuracy: 0.3776 - val_loss: 1.5543 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.3741 - loss: 1.5684 - val_accuracy: 0.3752 - val_loss: 1.5254 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.3717 - loss: 1.5438 - val_accuracy: 0.3742 - val_loss: 1.5592 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.3816 - loss: 1.5541 - val_accuracy: 0.3746 - val_loss: 1.5508 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.3780 - loss: 1.5479 - val_accuracy: 0.3754 - val_loss: 1.5386 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.3834 - loss: 1.5273 - val_accuracy: 0.3796 - val_loss: 1.5286 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m1311/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3830 - loss: 1.5192\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.3829 - loss: 1.5192 - val_accuracy: 0.3779 - val_loss: 1.5418 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.3796 - loss: 1.5163 - val_accuracy: 0.3813 - val_loss: 1.5295 - learning_rate: 2.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.3821 - loss: 1.5118 - val_accuracy: 0.3825 - val_loss: 1.5290 - learning_rate: 2.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.3893 - loss: 1.5041 - val_accuracy: 0.3839 - val_loss: 1.5284 - learning_rate: 2.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.3905 - loss: 1.5046 - val_accuracy: 0.3827 - val_loss: 1.5319 - learning_rate: 2.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.3878 - loss: 1.5004 - val_accuracy: 0.3832 - val_loss: 1.5221 - learning_rate: 2.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.3901 - loss: 1.5020 - val_accuracy: 0.3834 - val_loss: 1.5220 - learning_rate: 2.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.3872 - loss: 1.5046 - val_accuracy: 0.3865 - val_loss: 1.5205 - learning_rate: 2.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.3911 - loss: 1.4938 - val_accuracy: 0.3870 - val_loss: 1.5160 - learning_rate: 2.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.3909 - loss: 1.4934 - val_accuracy: 0.3863 - val_loss: 1.5130 - learning_rate: 2.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.3897 - loss: 1.4933 - val_accuracy: 0.3853 - val_loss: 1.5359 - learning_rate: 2.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.3965 - loss: 1.4870 - val_accuracy: 0.3887 - val_loss: 1.5149 - learning_rate: 2.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.4005 - loss: 1.4800 - val_accuracy: 0.3931 - val_loss: 1.5087 - learning_rate: 2.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.4008 - loss: 1.4875 - val_accuracy: 0.3982 - val_loss: 1.5087 - learning_rate: 2.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.4009 - loss: 1.4852 - val_accuracy: 0.3857 - val_loss: 1.5250 - learning_rate: 2.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.3911 - loss: 1.4912 - val_accuracy: 0.3803 - val_loss: 1.5200 - learning_rate: 2.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.3895 - loss: 1.4871 - val_accuracy: 0.3863 - val_loss: 1.5172 - learning_rate: 2.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m1312/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3901 - loss: 1.4866\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.3901 - loss: 1.4866 - val_accuracy: 0.3805 - val_loss: 1.5230 - learning_rate: 2.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.3853 - loss: 1.4889 - val_accuracy: 0.3806 - val_loss: 1.5202 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.3916 - loss: 1.4801 - val_accuracy: 0.3811 - val_loss: 1.5189 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.3884 - loss: 1.4806 - val_accuracy: 0.3800 - val_loss: 1.5205 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.3885 - loss: 1.4778 - val_accuracy: 0.3822 - val_loss: 1.5219 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.3906 - loss: 1.4786 - val_accuracy: 0.3817 - val_loss: 1.4747 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.3924 - loss: 1.4677 - val_accuracy: 0.3798 - val_loss: 1.5120 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.3875 - loss: 1.4648 - val_accuracy: 0.3811 - val_loss: 1.4650 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.3855 - loss: 1.4670 - val_accuracy: 0.3796 - val_loss: 1.5101 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.3909 - loss: 1.4652 - val_accuracy: 0.3815 - val_loss: 1.5239 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.3913 - loss: 1.4691 - val_accuracy: 0.3818 - val_loss: 1.4862 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.3861 - loss: 1.4569 - val_accuracy: 0.3804 - val_loss: 1.5195 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.3899 - loss: 1.4622 - val_accuracy: 0.3815 - val_loss: 1.4767 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.3894 - loss: 1.4518 - val_accuracy: 0.3811 - val_loss: 1.4548 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.3903 - loss: 1.4423 - val_accuracy: 0.3815 - val_loss: 1.4548 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.3907 - loss: 1.4381 - val_accuracy: 0.3821 - val_loss: 1.4667 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.3912 - loss: 1.4438 - val_accuracy: 0.3814 - val_loss: 1.4714 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.3881 - loss: 1.4441 - val_accuracy: 0.3811 - val_loss: 1.4966 - learning_rate: 1.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.3934 - loss: 1.4567 - val_accuracy: 0.3803 - val_loss: 1.5237 - learning_rate: 1.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.3927 - loss: 1.4613 - val_accuracy: 0.3802 - val_loss: 1.5197 - learning_rate: 1.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.3976 - loss: 1.4521 - val_accuracy: 0.3814 - val_loss: 1.5190 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 43.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    \"\"\"Predict the sentiment class and confidence for a single input text.\"\"\"\n",
        "    processed = preprocess_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([processed])\n",
        "    padded = pad_sequences(seq, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "    pred = model.predict(padded, verbose=0)\n",
        "\n",
        "    if NUM_CLASSES > 2:\n",
        "        class_idx = np.argmax(pred[0])\n",
        "        confidence = pred[0][class_idx]\n",
        "    else:\n",
        "        class_idx = int(pred[0] > 0.5)\n",
        "        confidence = pred[0][0] if class_idx == 1 else 1 - pred[0][0]\n",
        "\n",
        "    # Use the globally defined label_encoder\n",
        "    label = str(label_encoder.inverse_transform([class_idx])[0])\n",
        "\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"➤ Predicted Sentiment: {label.upper()}\")\n",
        "    print(f\"➤ Confidence: {confidence:.2f}\")\n",
        "    print(f\"➤ Probabilities: {dict(zip(label_encoder.classes_, map(float, pred[0])))}\")"
      ],
      "metadata": {
        "id": "hUrxt2bJkpeS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict sentiment for a single input\n",
        "input_text = \"I feel so anxious and worried about everything in my life\"\n",
        "predict_sentiment(input_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPOT0MEjluxq",
        "outputId": "ac43f3f6-0aeb-4c32-c12b-cc86c1ddd594"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I feel so anxious and worried about everything in my life\n",
            "➤ Predicted Sentiment: 3\n",
            "➤ Confidence: 0.37\n",
            "➤ Probabilities: {np.int64(0): 0.045296963304281235, np.int64(1): 0.02715577930212021, np.int64(2): 0.28780049085617065, np.int64(3): 0.3718903660774231, np.int64(4): 0.009853990748524666, np.int64(5): 0.03733086213469505, np.int64(6): 0.22067156434059143}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mental_health_sentiment_rnn.h5')\n",
        "print(\"Model saved as 'mental_health_sentiment_rnn.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itVL69Gku2pb",
        "outputId": "003e46c8-ebf8-41c0-b6a4-e265468f6c01"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'mental_health_sentiment_rnn.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "     pickle.dump(tokenizer, f)\n",
        "print(\"Tokenizer saved as 'tokenizer.pkl'\")\n",
        "\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "     pickle.dump(label_encoder, f)\n",
        "print(\"Label encoder saved as 'label_encoder.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67J7KQuLvdAc",
        "outputId": "63bd7a07-27fc-408e-e730-3cf2c0952876"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer saved as 'tokenizer.pkl'\n",
            "Label encoder saved as 'label_encoder.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "68oBkjsxvuHS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}